# Требования K8s и статус реализации

| Код | Требование | Критичность | Статус | Логика проверки |
|---|---|---|---|---|
| TACCS_1-P10-1-04 | Объекты управления должны поддерживать передачу событий аудита в целевой сервис аудита | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Для каждого `seaf.ta.services.k8s` проверяется наличие `audit`, что `seaf.ta.services.kb[audit]` существует и `tag=Log`; при наличии сетей у обоих объектов проверяется пересечение `network_connection`. Валидатор: `p3_k8s_audit_logging.yaml`. |
| TACCS_1-P10-10 04 | Объекты управления, предоставляющие внутренним пользователям (сотрудникам Компании и сотрудникам сторонних организаций, работающих по договору) доступ через пользовательский WEB-интерфейс или толстый клиент, должны интегрироваться с целевой системой аутентификации | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Для каждого k8s проверяется `auth`: ссылка существует в `seaf.ta.services.kb`, `tag=IdP`, и (если есть сети) существует пересечение `network_connection` между k8s и IdP. Валидатор: `p3_k8s_idp_integration.yaml`. |
| TACCS_1-P10-11 04 | Получение секретов ТУЗ АС и инфраструктурными решениями должно осуществляться из целевого сервиса хранения и предоставления секретов | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Проверяется поле `keys`: ссылка на `seaf.ta.services.kb` существует, `tag=Secrets`, и при наличии сетей есть их пересечение между k8s и сервисом секретов. Валидатор: `p3_k8s_secrets_service.yaml`. |
| TACCS_1-P10-13 04 | Управляющие интерфейсы должны быть изолированы или размещаться в одном или более выделенных управляющих сегментах (Management) в сети компании | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Проверяется массив `management_networks` (не пустой). Из сетей `management_networks` и `network_connection` извлекаются сегменты; валидация, что множества сегментов не пересекаются. Валидатор: `p3_k8s_management_networks.yaml`. |
| TACCS_1-P10-2-04 | Сертификаты, выпускаемые для объектов управления компании, за исключением публикуемых в сеть интернет (публичных), должны быть выпущены целевым удостоверяющим центром | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Проверка наличия `ca` у k8s и что он ссылается на существующий KB с `tag=CMC`; при наличии сетей проверяется их пересечение. Валидатор: `p3_k8s_cmc_presence.yaml`. |
| TACCS_1-P10-24 04 | Должен быть предусмотрен механизм защиты, исключающий передачу конфиденциальных данных в событиях аудита | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Проверяется наличие `audit_policy`: ссылка на существующий KB; при наличии сетей проверяется их пересечение. Логика самого содержания политики не проверяется. Валидатор: `p3_k8s_audit_sanitization.yaml`. |
| TACCS_1-P10-25 04 | Каждый кластер вычислительных систем должен размещаться только в одной зоне безопасности | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Собираются все сети из `network_connection` для k8s, затем их сегменты и поле `zone` сегментов (или `sber.zone`). Проверяется, что все зоны одинаковые; также выявляются сегменты без `zone`. Валидатор: `p3_k8s_single_security_segment.yaml`. |
| TACCS_1-P10-28 04 | Платформа контейнерной оркестрации должна обеспечивать возможность управления политиками безопасности | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Поле `policy` у k8s: ссылка существует в KB, `tag=Policy`; при наличии сетей — пересечение `network_connection` k8s и сервиса политики. Валидатор: `p3_k8s_policy_engine.yaml`. |
| TACCS_1-P10-29 04 | Программное обеспечение в Компании должно быть получено из целевых репозиториев | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Поле `registries` у k8s: не пустой массив; каждая ссылка существует в KB и имеет `tag=Repo` или `tag=Registry`. Сетевые проверки не выполняются. Валидатор: `p3_k8s_allowed_registries.yaml`. |
| TACCS_1-P10-3-04 | Объекты управления компании, при использовании цифровых сертификатов должны использовать и проверять сертификаты целевого УЦ в соответствии с порядком управления сертификатами целевого УЦ | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Проверяется только наличие ссылки `ca` на целевой УЦ (KB `tag=CMC`). Глубокая проверка доверия не выполняется. Валидатор: `p3_k8s_ca_trust.yaml`. |
| TACCS_1-P10-5-04 | Объекты управления в которые осуществляется доступ пользователей компании и сторонних организаций, с корпоративными учетными записями, для централизованного управления и контроля доступа, должны быть интегрированы с целевой системой управления доступом | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Поле `idm`: ссылка существует в KB, `tag=IdM`; при наличии сетей — пересечение `network_connection` между k8s и IdM. Валидатор: `p3_k8s_access_mgmt_integration.yaml`. |
| TACCS_1-P10-7-04 | Доступ пользователей компании и сторонних компаний с корпоративными привилегированными учетными записями к объектам управления, должен осуществляется через целевую систему управления привилегированным доступом | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Поле `pam`: ссылка существует в KB, `tag=PAM`; при наличии сетей — пересечение `network_connection` между k8s и PAM. Валидатор: `p3_k8s_pam.yaml`. |
| TACCS_1-P10-8 04 | Управление жизненным циклом корпоративных технических учетных записей должно осуществляться через целевую систему управления учетными записями | Mission Critical, Business Critical, Business Operational, Office Productivity | Отложено | — |
| TACSA_4-P3-2-04 | Серверное оборудование должно базироваться на процессорах архитектуры: x86-64; ARM | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано | Для каждого `seaf.ta.components.k8s_node` проверяется наличие `architecture` и что значение одно из: `x86-64`, `amd64` (синоним), `ARM`. Валидатор: `p3_k8s_node_architecture.yaml`. |
| TACSA_4-P3-29-04 | Все встроенные сервисы платформы должны устанавливаться в отдельном пространстве имён (namespace) для каждого компонента; соответствующие операторы этих сервисов располагаются в специально выделенных namespace. | Mission Critical, Business Critical, Business Operational, Office Productivity | Реализовано (частично) | Для каждого Deployment проверяется `namespace_ref`; `k8s_namespace` существует и содержит `labels` (не пусто). Содержание меток не валидируется. Валидатор: `p3_k8s_namespace_labels.yaml`. |
| TACSA_4-P3-31-04 | Журналы платформы контейнерной оркестрации должны централизованно храниться во внешней системе сбора и анализа логов (вне самой платформы). | Mission Critical, Business Critical | Реализовано | Поле `monitoring` у k8s содержит ссылки на `seaf.ta.services.monitoring`; для каждой ссылки объект существует и содержит роль `Журналирование`. Сетевые пересечения не проверяются. Валидатор: `p3_k8s_logging_service.yaml`. |
| TACSA_4-P3-32-04 | В платформе контейнерной оркестрации имеются механизмы и активированы настройки лимитов и запросов на ресурсы CPU/RAM. | Mission Critical, Business Critical | Реализовано | Для каждого `k8s_deployment` и всех его контейнеров проверяются `resources.limits.cpu` и `resources.limits.ram` на заполненность. Валидатор: `p3_k8s_deployment_resource_limits.yaml`. |
| TACSA_4-P3-33-04 | Необходимо обеспечить резервное копирование конфигурации платформы контейнерной оркестрации. | Mission Critical, Business Critical | Реализовано | Поле `backup` у k8s содержит ссылки на `seaf.ta.services.backup`; каждая ссылка должна существовать. Сетевые пересечения не проверяются. Валидатор: `p3_k8s_backup_service.yaml`. |
| TACSA_4-P3-34-04 | Платформа контейнерной оркестрации должна предусматривать возможность обновления её компонентов без простоев для приложений (например, за счёт поэтапного перезапуска узлов кластера – rolling update). | Mission Critical, Business Critical | Отложено | — |
| TACSA_4-P3-35-04 | Все компоненты платформы контейнерной оркестрации (узлы и сервисы) должны синхронизировать системное время с целевым сервером времени (NTP). | Mission Critical, Business Critical, Business Operational, Office Productivity | Отложено | — |
| TACSA_4-P3-36-04 | Инфраструктурные сервисы платформы контейнерной оркестрации (системные компоненты кластера) должны быть размещены на отдельных выделенных узлах кластера, которые не используются для размещения пользовательских приложений. | Mission Critical, Business Critical, Business Operational, Office Productivity | Отложено | — |
| TACSA_4-P3-37-04 | Управление конфигурациями платформы контейнерной оркестрации должно осуществляться через корпоративную систему управления конфигурациями. | Mission Critical, Business Critical, Business Operational, Office Productivity | Отложено | — |
| TACSA_4-P3-38-04 | Платформа контейнерной оркестрации должна поддерживать реализацию сервисов балансировки и проксирования входящих и исходящих запросов (ingress/egress proxy). | Mission Critical, Business Critical, Business Operational, Office Productivity | Отложено | — |
| TACSA_4-P9-46-04 | Кластер платформы контейнерной оркестрации должен состоять из набора машин (узлов) и развёртывается на нескольких узлах. - мастер узлы (master nodes) - минимум 3 узла; - рабочие узлы (woker nodes) - минимум 2 узла | Mission Critical, Business Critical | Реализовано (частично) | Для каждого кластера суммарно считаются `k8s_node` с `cluster_ref` на него; если суммарно < 5 — нарушение. Роли master/worker не учитываются. Валидатор: `p3_k8s_ha_node_count.yaml`. |
| TACSA_4-P9-47-04 | Платформа контейнерной оркестрации должна иметь в резервных зонах доступности вычислительные мощности, обеспечивающие резервирование в соответствии с уровнями, указанными в Приложении 1 | Mission Critical, Business Critical | Реализовано (частично) | Узлы кластера должны располагаться минимум в двух `zone` и эти значения должны входить в список `k8s.availabilityzone`. Валидатор: `p3_k8s_multi_az_distribution.yaml`. |
